# Detection

Во-первых, датасет [отсюда](https://www.lvisdataset.org/dataset). Кроме 18 гигов картинок есть разметка на 1.1гб в json. Тут не только bbox'ы для детекции, но и разметка для сегментации - отсюда и такой размер. Колабовских 12 гигов памяти не хватает чтобы прочесть это питоновским `json.load`, поэтому надо пользоваться lvis:

```bash
pip install lvis
```

```python
from lvis import LVIS
lvis_api = LVIS("*.json")
```

Посмотреть что внутри не открывая можно [тут](https://www.kaggle.com/datasets/alexanderyyy/lvis-v1), локально у меня крашилось всё от попыток открыть файл.
Пример того, как с ним работать, можно найти в коде detectron от фейсбука, например [тут](https://huggingface.co/spaces/CVPR/regionclip-demo/blob/1b73edf3460eb4db3fbaa69b815f6ffddfb49091/detectron2/data/datasets/lvis.py). [Здесь](https://www.kaggle.com/code/glebkum/helmets-detection-faster-r-cnn/notebook) ноутбук с аналогичной задачей, но меньшим запарыванием по bbox, т.к. всё нужное упаковали заранее в csv.
Нам же, в целом, нужно только правильно подготовить данные.

[Формат bbox в lvis](https://github.com/cocodataset/cocoapi/issues/102#issuecomment-519603653) это **[x, y, w, h]**, где x, y - верхний левый угол бокса, w, h его ширина и высота, соотв чтобы получить нижний правый угол надо ПРИБАВИТЬ к (x, y) w и h: (x+w, y+h) (Поскольку начало координат в верхнем левом углу изображения, соотв максимальные координаты в нижнем правом). Именно такой, через два угла формат нужен для faster rcnn. [Тут](https://medium.com/analytics-vidhya/basics-of-bounding-boxes-94e583b5e16c) можно почитать про разные варианты задания боксов.
Некоторые картинки идут в одноканальном виде (grayscale), их не много, со шлемами всего две, но можно просто [стакнуть каналы](https://stackoverflow.com/questions/40119743/convert-a-grayscale-image-to-a-3-channel-image) чтобы получилось типа RGB. Проверить что нампай всё корректно стакнул можно [так](https://stackoverflow.com/questions/2659312/how-do-i-convert-a-numpy-array-to-and-display-an-image)

для YOLO формат такой: центральная точка, ширина и высота бокса, при этом всё отнормировано с учётом размера изображения
в принципе всё что нужно есть в [этом](https://www.kaggle.com/code/eneszvo/yolov5-helmet-detection-train-and-inference) ноутбуке, кроме чтения lvis json, но он читается как и в первом случае. Учится норм если зафризить первую половину (`--freze 12`), если фризить всё кроме финального, то не оч хорошо работает - для детекции только шлемов с приемлемым качеством, видимо, "обобщённо" извлекаемых фичей учась на COCO не достаточно.
Версию из torch hub не щупал, в репозитории и так достаточно найсовые скрипты для обучения/инференса, которые даже какие-то ошибки указывают, например что индексы классов должны начинаться с 0. Кстати, она сама делает трехканальные изображения из одноканальных, не нужно стакать руками как это было для faster rcnn
